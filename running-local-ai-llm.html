<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Running a local AI LLM &mdash; 0xCC0FF</title>
  <meta name="author" content="Chris Coffey (ccoff)">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://ccoff.github.io/favicon.png" rel="icon">

  <link href="https://ccoff.github.io/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <!-- Matomo -->
  <script type="text/javascript">
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="//wanderingwalrus.com/matomo/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '2']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>
  <!-- End Matomo Code -->
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://ccoff.github.io/">0xCC0FF</a></h1>
    <h2>A companion blog to my GitHub account</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
    <li><a href="/pages/about">About</a></li>
    <li><a href="/pages/rss">RSS</a></li>
      <li class="active">
        <a href="https://ccoff.github.io/category/blog">Blog</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Running a local AI LLM</h1>
    <p class="meta">
<time datetime="2025-03-18T00:00:00+00:00" pubdate>Tue 18 March 2025</time>    </p>
</header>

  <div class="entry-content"><p>I've recently been using a local setup for testing and evaluating various <a href="https://en.wikipedia.org/wiki/Large_language_model">LLMs</a>. This affords me some privacy, without the need to create accounts or send information into the ether. Tools such as <a href="https://ollama.com/">Ollama</a> and <a href="https://www.openwebui.com/">Open WebUI</a> make setting this up a straightforward process.</p>
<p>This article is a quick overview of how to install and run an LLM locally. (It also serves as notes to myself when I need a refresher.) The following procedures are for Linux because that's what I run. The general steps for Windows and MacOS are probably similar; consult the relevant documentation for <a href="https://github.com/ollama/ollama/tree/main/docs">Ollama</a> and <a href="https://docs.openwebui.com/">Open WebUI</a>.</p>
<h1>LLM installation with Ollama</h1>
<p><a href="https://ollama.com/">Ollama</a> makes it very easy to download an LLM and have it up and running in minutes. This command installs and starts the Ollama service:</p>
<div class="highlight"><pre><span></span><code>curl -fsSL https://ollama.com/install.sh | sh
</code></pre></div>

<p>Then to download and run a model, all you need to do is:</p>
<div class="highlight"><pre><span></span><code>ollama run mistral
</code></pre></div>

<p>I chose <a href="https://mistral.ai/">Mistral's model</a> here, but you can choose from <a href="https://ollama.com/search">several other models</a>. It's worth trying several of them out (Microsoft's <a href="https://ollama.com/library/phi4">phi4</a>, <a href="https://www.deepseek.com/">DeepSeek</a>, etc.) to see how they perform. Just replace <em>mistral</em> with the name of the model you want to run.</p>
<p>The <code>&gt;&gt;&gt;</code> prompt indicates the LLM is ready and waiting:</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; which is faster, a computer or a sprinter?
A sprinter is much faster than a computer. While a computer processes 
information very quickly, this speed is not comparable to the physical 
speed of a human sprinter. For example, Usain Bolt, one of the fastest 
humans ever, can run at speeds up to 27.8 mph (44.7 km/h), while even the 
fastest electronic data processing occurs on the order of nanoseconds or 
billionths of a second. However, in different contexts, a computer may be 
much faster than a human for certain tasks such as calculating 
mathematical problems at incredible speeds.
</code></pre></div>

<h2>Ollama API</h2>
<p>You're not limited to interacting with the LLM by manually typing in prompts. Ollama provides API access on localhost port 11434 so you can programmatically engage with the LLM. For example, you can do a quick and dirty <em>curl</em> request:</p>
<div class="highlight"><pre><span></span><code>curl -X POST http://localhost:11434/api/generate -d &#39;{&quot;model&quot;: &quot;phi4&quot;, &quot;prompt&quot;: &quot;what would you call a cross between a blueberry and a peach?&quot;}&#39;
</code></pre></div>

<p>For greater control there's always Python. For example:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:11434/api/generate&quot;</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;phi4&quot;</span><span class="p">,</span>
    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;write a humorous limerick about a walrus&quot;</span><span class="p">,</span>
    <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="kc">False</span>
<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Content-type&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="n">requests</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</code></pre></div>

<h1>Web interface installation with Open WebUI</h1>
<p>For a more polished experience, you can use <a href="https://www.openwebui.com/">Open WebUI</a>. This provides a user-friendly web interface with no need for command-line interaction. Perfect for enabling non-technical people around you to also use your local LLMs.</p>
<p>There are several ways to get Open WebUI up and running, including Docker and Kubernetes. The following procedure opts for a lighter footprint.</p>
<p>First, install <code>nvm</code> (Node version manager) to get a more recent Node.js version (as of writing, Open WebUI requires version 20.10 or newer):</p>
<div class="highlight"><pre><span></span><code>wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash
source ~/.bashrc
nvm list-remote
nvm install v20.19.0
nvm list
</code></pre></div>

<p>The <code>nvm list</code> command lists all of the Node.js versions available on the host. If you need to switch between versions, type the following command, replacing <code>[version]</code> with the version you want to run:</p>
<div class="highlight"><pre><span></span><code><span class="n">nvm</span><span class="w"> </span><span class="k">use</span><span class="w"> </span><span class="o">[</span><span class="n">version</span><span class="o">]</span>
</code></pre></div>

<p>Alternatively, to use the installed system version:</p>
<div class="highlight"><pre><span></span><code>nvm use system
</code></pre></div>

<p>Next, download and configure Open WebUI:</p>
<div class="highlight"><pre><span></span><code>cd ~
git clone https://github.com/open-webui/open-webui.git
cd open-webui/
cp -RPp .env.example .env
</code></pre></div>

<p>Then install the front end:</p>
<div class="highlight"><pre><span></span><code>npm install
npm run build
</code></pre></div>

<p>Next, set up the Python virtual environment:</p>
<div class="highlight"><pre><span></span><code>cd ~
python3 -m venv webui-env
source webui-env/bin/activate
cd ~/open-webui/backend
pip install -r requirements.txt -U
</code></pre></div>

<p>(If the <code>pip install -r requirements.txt -U</code> command fails, review the error messages for missing packages and install them. For example, I had to install the <code>postgresql-common</code> and <code>libpq-dev</code> packages.)</p>
<p>Finally, start Open WebUI:</p>
<div class="highlight"><pre><span></span><code>bash start.sh
</code></pre></div>

<p>After yet more file downloads and installations, Open WebUI should be up and running. Open a web browser and go to <a href="http://localhost:8080/">http://localhost:8080/</a>. Follow the steps to set up an admin account, and then you should see a page with the LLM awaiting your prompt:</p>
<figure>
<a href="images/ai-llm-mistral-initial-page.png"><img src="images/ai-llm-mistral-initial-page.png" alt="Image: Initial page of Open WebUI with Mistral awaiting a prompt" width="520" /></a>
<figcaption>Initial page of Open WebUI with the Mistral LLM awaiting a prompt. Click the image for the full-resolution picture.</figcaption>
</figure>

<p>You can then enter a prompt, provide feedback on the LLM's response, view statistics, and more:</p>
<figure>
<a href="images/ai-llm-mistral-response.png"><img src="images/ai-llm-mistral-response.png" alt="Image: Mistral's response to a prompt asking it to generate song titles" width="520" /></a>
<figcaption>Mistral's response to a prompt asking it to generate song titles. Click the image for the full-resolution picture.</figcaption>
</figure>

<p>Happy AI-ing!</p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Chris Coffey (ccoff)
    </span>
  </span>
<time datetime="2025-03-18T00:00:00+00:00" pubdate>Tue 18 March 2025</time>  <span class="categories">
    <a class='category' href='https://ccoff.github.io/category/blog'>blog</a>
  </span>
  <span class="categories">
    <a class="category" href="https://ccoff.github.io/tag/ai">ai</a>,    <a class="category" href="https://ccoff.github.io/tag/llm">llm</a>,    <a class="category" href="https://ccoff.github.io/tag/linux">linux</a>,    <a class="category" href="https://ccoff.github.io/tag/python">python</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://ccoff.github.io/running-local-ai-llm">Running a local AI LLM</a>
      </li>
      <li class="post">
          <a href="https://ccoff.github.io/chasing-weather-satellites-sequel">Chasing weather satellites: the sequel</a>
      </li>
      <li class="post">
          <a href="https://ccoff.github.io/binary-patching">Binary patching for fun and zero profit</a>
      </li>
      <li class="post">
          <a href="https://ccoff.github.io/listening-to-shortwave-with-sdr">Not your father's radio: listening to shortwave with software-defined radio</a>
      </li>
      <li class="post">
          <a href="https://ccoff.github.io/chasing-weather-satellites-with-sdr">Chasing weather satellites with software-defined radio</a>
      </li>
    </ul>
  </section>
  <!--
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://ccoff.github.io/category/blog">blog</a></li>
    </ul>
  </section>
  -->
 

  <section>
  <h1>Tags</h1>
    <a href="https://ccoff.github.io/tag/ai">ai</a>,    <a href="https://ccoff.github.io/tag/llm">llm</a>,    <a href="https://ccoff.github.io/tag/linux">linux</a>,    <a href="https://ccoff.github.io/tag/python">python</a>,    <a href="https://ccoff.github.io/tag/radio">radio</a>,    <a href="https://ccoff.github.io/tag/sdr">sdr</a>,    <a href="https://ccoff.github.io/tag/satellites">satellites</a>,    <a href="https://ccoff.github.io/tag/reverse-engineer">reverse engineer</a>,    <a href="https://ccoff.github.io/tag/shortwave">shortwave</a>,    <a href="https://ccoff.github.io/tag/iso">iso</a>,    <a href="https://ccoff.github.io/tag/live-image">live image</a>,    <a href="https://ccoff.github.io/tag/hardware">hardware</a>,    <a href="https://ccoff.github.io/tag/uart">UART</a>,    <a href="https://ccoff.github.io/tag/repair">repair</a>,    <a href="https://ccoff.github.io/tag/monitor">monitor</a>,    <a href="https://ccoff.github.io/tag/imap">imap</a>,    <a href="https://ccoff.github.io/tag/e-mail">e-mail</a>,    <a href="https://ccoff.github.io/tag/php">php</a>,    <a href="https://ccoff.github.io/tag/accessibility">accessibility</a>,    <a href="https://ccoff.github.io/tag/hci">hci</a>,    <a href="https://ccoff.github.io/tag/opencv">opencv</a>,    <a href="https://ccoff.github.io/tag/sensors">sensors</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://github.com/ccoff">GitHub</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy; 2025 Chris Coffey (ccoff) &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="https://ccoff.github.io/theme/js/modernizr-2.0.js"></script>
  <script src="https://ccoff.github.io/theme/js/ender.js"></script>
  <script src="https://ccoff.github.io/theme/js/octopress.js" type="text/javascript"></script>
</body>
</html>